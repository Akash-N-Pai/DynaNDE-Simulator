{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "encoder_processing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENCODER TRACE EXTRACTION\n",
      "Processing ALL tokens from 64 sequences\n",
      "Sequence length: 128 tokens\n",
      "Total tokens per layer: 8192\n",
      "Shards to process: 1 (starting from shard 2)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing LAYER 2\n",
      "================================================================================\n",
      "\n",
      "  Loaded shard 0-2.pt: 8192 tokens from 64 sequences\n",
      "\n",
      "  Total tokens collected: 8192\n",
      "  Total sequences: 64\n",
      "  Expected: 64 sequences, 8192 tokens\n",
      "  Generating CSV file...\n",
      "  Generating statistics...\n",
      "  ✓ Saved Layer 2\n",
      "    Files: .pt, .csv, _top1/2/6_stats (txt & csv)\n",
      "    Total tokens in file: 8192\n",
      "\n",
      "================================================================================\n",
      "Processing LAYER 3\n",
      "================================================================================\n",
      "\n",
      "  Loaded shard 0-2.pt: 8192 tokens from 64 sequences\n",
      "\n",
      "  Total tokens collected: 8192\n",
      "  Total sequences: 64\n",
      "  Expected: 64 sequences, 8192 tokens\n",
      "  Generating CSV file...\n",
      "  Generating statistics...\n",
      "  ✓ Saved Layer 3\n",
      "    Files: .pt, .csv, _top1/2/6_stats (txt & csv)\n",
      "    Total tokens in file: 8192\n",
      "\n",
      "================================================================================\n",
      "Processing LAYER 4\n",
      "================================================================================\n",
      "\n",
      "  Loaded shard 0-2.pt: 8192 tokens from 64 sequences\n",
      "\n",
      "  Total tokens collected: 8192\n",
      "  Total sequences: 64\n",
      "  Expected: 64 sequences, 8192 tokens\n",
      "  Generating CSV file...\n",
      "  Generating statistics...\n",
      "  ✓ Saved Layer 4\n",
      "    Files: .pt, .csv, _top1/2/6_stats (txt & csv)\n",
      "    Total tokens in file: 8192\n",
      "\n",
      "================================================================================\n",
      "Processing LAYER 5\n",
      "================================================================================\n",
      "\n",
      "  Loaded shard 0-2.pt: 8192 tokens from 64 sequences\n",
      "\n",
      "  Total tokens collected: 8192\n",
      "  Total sequences: 64\n",
      "  Expected: 64 sequences, 8192 tokens\n",
      "  Generating CSV file...\n",
      "  Generating statistics...\n",
      "  ✓ Saved Layer 5\n",
      "    Files: .pt, .csv, _top1/2/6_stats (txt & csv)\n",
      "    Total tokens in file: 8192\n",
      "\n",
      "================================================================================\n",
      "Processing LAYER 6\n",
      "================================================================================\n",
      "\n",
      "  Loaded shard 0-2.pt: 8192 tokens from 64 sequences\n",
      "\n",
      "  Total tokens collected: 8192\n",
      "  Total sequences: 64\n",
      "  Expected: 64 sequences, 8192 tokens\n",
      "  Generating CSV file...\n",
      "  Generating statistics...\n",
      "  ✓ Saved Layer 6\n",
      "    Files: .pt, .csv, _top1/2/6_stats (txt & csv)\n",
      "    Total tokens in file: 8192\n",
      "\n",
      "================================================================================\n",
      "Processing LAYER 7\n",
      "================================================================================\n",
      "\n",
      "  Loaded shard 0-2.pt: 8192 tokens from 64 sequences\n",
      "\n",
      "  Total tokens collected: 8192\n",
      "  Total sequences: 64\n",
      "  Expected: 64 sequences, 8192 tokens\n",
      "  Generating CSV file...\n",
      "  Generating statistics...\n",
      "  ✓ Saved Layer 7\n",
      "    Files: .pt, .csv, _top1/2/6_stats (txt & csv)\n",
      "    Total tokens in file: 8192\n",
      "\n",
      "================================================================================\n",
      "Processing LAYER 8\n",
      "================================================================================\n",
      "\n",
      "  Loaded shard 0-2.pt: 8192 tokens from 64 sequences\n",
      "\n",
      "  Total tokens collected: 8192\n",
      "  Total sequences: 64\n",
      "  Expected: 64 sequences, 8192 tokens\n",
      "  Generating CSV file...\n",
      "  Generating statistics...\n",
      "  ✓ Saved Layer 8\n",
      "    Files: .pt, .csv, _top1/2/6_stats (txt & csv)\n",
      "    Total tokens in file: 8192\n",
      "\n",
      "================================================================================\n",
      "Processing LAYER 9\n",
      "================================================================================\n",
      "\n",
      "  Loaded shard 0-2.pt: 8192 tokens from 64 sequences\n",
      "\n",
      "  Total tokens collected: 8192\n",
      "  Total sequences: 64\n",
      "  Expected: 64 sequences, 8192 tokens\n",
      "  Generating CSV file...\n",
      "  Generating statistics...\n",
      "  ✓ Saved Layer 9\n",
      "    Files: .pt, .csv, _top1/2/6_stats (txt & csv)\n",
      "    Total tokens in file: 8192\n",
      "\n",
      "================================================================================\n",
      "All layers processed successfully!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Set print options\n",
    "torch.set_printoptions(threshold=float('inf'))\n",
    "\n",
    "model = \"flame-moe-290m\"\n",
    "runid, epoch = 31066, 5473\n",
    "\n",
    "# Parameters\n",
    "sequence_length = 128\n",
    "num_sequences_per_shard = 128\n",
    "total_sequences_needed = 64  # ONLY load this many sequences\n",
    "\n",
    "# Shard configuration\n",
    "start_shard_idx = 2\n",
    "num_shards = 1\n",
    "\n",
    "# Base output directory\n",
    "base_output_dir = Path(\"Encoder_Batch_2-64\")\n",
    "base_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process layers\n",
    "layers_to_process = list(range(2, 10))  # Layers 2-9\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ENCODER TRACE EXTRACTION\")\n",
    "print(f\"Processing ALL tokens from {total_sequences_needed} sequences\")\n",
    "print(f\"Sequence length: {sequence_length} tokens\")\n",
    "print(f\"Total tokens per layer: {total_sequences_needed * sequence_length}\")\n",
    "print(f\"Shards to process: {num_shards} (starting from shard {start_shard_idx})\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# LOOP: Layers (one file per layer with ALL tokens from ALL sequences)\n",
    "for layer in layers_to_process:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing LAYER {layer}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Create layer directory\n",
    "    layer_dir = base_output_dir / f\"Layer_{layer}\"\n",
    "    layer_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Lists to collect ALL tokens from ALL sequences from ALL shards\n",
    "    all_samples = []\n",
    "    all_scores = []\n",
    "    all_indices = []\n",
    "    shard_list = []\n",
    "    \n",
    "    # Calculate sequences per shard (distribute evenly across shards)\n",
    "    sequences_per_shard = total_sequences_needed // num_shards\n",
    "    remaining_sequences = total_sequences_needed % num_shards\n",
    "    \n",
    "    # Process each shard\n",
    "    sequences_collected = 0\n",
    "    for idx, shard_idx in enumerate(range(start_shard_idx, start_shard_idx + num_shards)):\n",
    "        shard = f\"0-{shard_idx}.pt\"\n",
    "        shard_list.append(shard)\n",
    "        \n",
    "        # Calculate sequences to take from this shard\n",
    "        seqs_from_this_shard = sequences_per_shard + (1 if idx < remaining_sequences else 0)\n",
    "        tokens_from_this_shard = seqs_from_this_shard * sequence_length\n",
    "        \n",
    "        try:\n",
    "            samples = torch.load(Path(f\"samples/{model}/{runid}\", shard), map_location=\"cpu\")\n",
    "            actives = torch.load(Path(f\"actives/{model}/{runid}/{epoch}/{layer}\", shard), map_location=\"cpu\")\n",
    "            scores, indices = actives\n",
    "            \n",
    "            # Only take the needed sequences from this shard\n",
    "            samples_subset = samples[:tokens_from_this_shard]\n",
    "            scores_subset = scores[:tokens_from_this_shard]\n",
    "            indices_subset = indices[:tokens_from_this_shard]\n",
    "            \n",
    "            all_samples.append(samples_subset)\n",
    "            all_scores.append(scores_subset)\n",
    "            all_indices.append(indices_subset)\n",
    "            \n",
    "            sequences_collected += seqs_from_this_shard\n",
    "            print(f\"  Loaded shard {shard}: {len(samples_subset)} tokens from {seqs_from_this_shard} sequences\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"  Warning: Shard {shard} not found\")\n",
    "            break\n",
    "    \n",
    "    if len(all_samples) == 0:\n",
    "        print(f\"  No data found, skipping Layer {layer}\")\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all shards\n",
    "    samples_all = torch.cat(all_samples, dim=0)\n",
    "    scores_all = torch.cat(all_scores, dim=0)\n",
    "    indices_all = torch.cat(all_indices, dim=0)\n",
    "    \n",
    "    total_tokens = len(samples_all)\n",
    "    total_sequences = total_tokens // sequence_length\n",
    "    \n",
    "    print(f\"\\n  Total tokens collected: {total_tokens}\")\n",
    "    print(f\"  Total sequences: {total_sequences}\")\n",
    "    print(f\"  Expected: {total_sequences_needed} sequences, {total_sequences_needed * sequence_length} tokens\")\n",
    "    \n",
    "    # Verify we got the right amount\n",
    "    if total_sequences != total_sequences_needed:\n",
    "        print(f\"  WARNING: Collected {total_sequences} sequences but expected {total_sequences_needed}!\")\n",
    "    \n",
    "    # Create output filename\n",
    "    first_shard_num = shard_list[0].replace('.pt', '')\n",
    "    last_shard_num = shard_list[-1].replace('.pt', '')\n",
    "    output_filename = (\n",
    "        f\"{model}_runid{runid}_epoch{epoch}_layer{layer}_shard{first_shard_num}_to_{last_shard_num}_encoder_{total_sequences}seqs_{total_tokens}tokens\"\n",
    "    )\n",
    "    \n",
    "    output_path_base = layer_dir / output_filename\n",
    "    \n",
    "    # Save .pt file\n",
    "    output_data = {\n",
    "        'model': model,\n",
    "        'runid': runid,\n",
    "        'epoch': epoch,\n",
    "        'layer': layer,\n",
    "        'num_sequences': total_sequences,\n",
    "        'num_tokens': total_tokens,\n",
    "        'sequence_length': sequence_length,\n",
    "        'shards': shard_list,\n",
    "        'samples': samples_all,\n",
    "        'scores': scores_all,\n",
    "        'indices': indices_all\n",
    "    }\n",
    "    torch.save(output_data, f'{output_path_base}.pt')\n",
    "    \n",
    "    # Generate CSV file\n",
    "    csv_filename = f'{output_path_base}.csv'\n",
    "    num_experts = 64\n",
    "    \n",
    "    print(f\"  Generating CSV file...\")\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        header = ['layer_id', 'token_id'] + [f'expert_{i}' for i in range(num_experts)]\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        for token_idx in range(len(samples_all)):\n",
    "            row = [0, token_idx]\n",
    "            expert_scores = [0.0] * num_experts\n",
    "            \n",
    "            for i in range(len(indices_all[token_idx])):\n",
    "                expert_id = int(indices_all[token_idx][i].item())\n",
    "                score = float(scores_all[token_idx][i].item())\n",
    "                expert_scores[expert_id] = score\n",
    "            \n",
    "            formatted_scores = [f'{score:.6f}' for score in expert_scores]\n",
    "            row.extend(formatted_scores)\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    # Generate statistics\n",
    "    print(f\"  Generating statistics...\")\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    expert_columns = [f'expert_{i}' for i in range(64)]\n",
    "    \n",
    "    # TOP 1\n",
    "    expert_counts_top1 = {i: 0 for i in range(64)}\n",
    "    for idx, row in df.iterrows():\n",
    "        expert_scores = row[expert_columns].values.astype(float)\n",
    "        top_1_index = np.argsort(expert_scores)[-1]\n",
    "        expert_counts_top1[top_1_index] += 1\n",
    "    \n",
    "    sorted_experts_top1 = sorted(expert_counts_top1.items(), key=lambda x: x[1], reverse=True)\n",
    "    expert_activ_top1 = sum(1 for count in expert_counts_top1.values() if count > 0)\n",
    "    \n",
    "    # TOP 2\n",
    "    expert_counts_top2 = {i: 0 for i in range(64)}\n",
    "    for idx, row in df.iterrows():\n",
    "        expert_scores = row[expert_columns].values.astype(float)\n",
    "        top_2_indices = np.argsort(expert_scores)[-2:][::-1]\n",
    "        for expert_id in top_2_indices:\n",
    "            expert_counts_top2[expert_id] += 1\n",
    "    \n",
    "    sorted_experts_top2 = sorted(expert_counts_top2.items(), key=lambda x: x[1], reverse=True)\n",
    "    expert_activ_top2 = sum(1 for count in expert_counts_top2.values() if count > 0)\n",
    "    \n",
    "    # TOP 6\n",
    "    expert_counts_top6 = {i: 0 for i in range(64)}\n",
    "    for idx, row in df.iterrows():\n",
    "        expert_scores = row[expert_columns].values.astype(float)\n",
    "        top_6_indices = np.argsort(expert_scores)[-6:][::-1]\n",
    "        for expert_id in top_6_indices:\n",
    "            expert_counts_top6[expert_id] += 1\n",
    "    \n",
    "    sorted_experts_top6 = sorted(expert_counts_top6.items(), key=lambda x: x[1], reverse=True)\n",
    "    expert_activ_top6 = sum(1 for count in expert_counts_top6.values() if count > 0)\n",
    "    \n",
    "    # Gating params\n",
    "    BW_PCIe, BW_MD, alpha = 32, 512, 1.0\n",
    "    \n",
    "    expert_gpu_top1 = round((BW_PCIe / (BW_MD + BW_PCIe)) * expert_activ_top1)\n",
    "    H_top1 = int(alpha * expert_gpu_top1)\n",
    "    \n",
    "    expert_gpu_top2 = round((BW_PCIe / (BW_MD + BW_PCIe)) * expert_activ_top2)\n",
    "    H_top2 = int(alpha * expert_gpu_top2)\n",
    "    \n",
    "    expert_gpu_top6 = round((BW_PCIe / (BW_MD + BW_PCIe)) * expert_activ_top6)\n",
    "    H_top6 = int(alpha * expert_gpu_top6)\n",
    "    \n",
    "    # Save stats files (TOP1, TOP2, TOP6)\n",
    "    for top_k, sorted_experts, expert_activ, H in [\n",
    "        (1, sorted_experts_top1, expert_activ_top1, H_top1),\n",
    "        (2, sorted_experts_top2, expert_activ_top2, H_top2),\n",
    "        (6, sorted_experts_top6, expert_activ_top6, H_top6)\n",
    "    ]:\n",
    "        stats_txt = f\"{output_path_base}_top{top_k}_stats.txt\"\n",
    "        stats_csv = f\"{output_path_base}_top{top_k}_stats.csv\"\n",
    "        \n",
    "        with open(stats_txt, 'w') as f:\n",
    "            f.write(\"=\" * 60 + \"\\n\")\n",
    "            f.write(f\"TOP {top_k} EXPERT TOKEN DISTRIBUTION (Layer {layer} - ALL SEQUENCES)\\n\")\n",
    "            f.write(\"=\" * 60 + \"\\n\")\n",
    "            f.write(f\"Total tokens: {len(df)}\\n\")\n",
    "            f.write(f\"Total sequences: {total_sequences}\\n\")\n",
    "            f.write(f\"Sequence length: {sequence_length}\\n\")\n",
    "            f.write(f\"Expected total (tokens × {top_k}): {len(df) * top_k}\\n\")\n",
    "            f.write(\"=\" * 60 + \"\\n\")\n",
    "            f.write(f\"{'Expert ID':<12} {'Token Count':<15} {'Percentage':<10}\\n\")\n",
    "            f.write(\"-\" * 60 + \"\\n\")\n",
    "            \n",
    "            for expert_id, count in sorted_experts:\n",
    "                percentage = (count / len(df)) * 100 if len(df) > 0 else 0.0\n",
    "                f.write(f\"Expert {expert_id:<5} {count:<15} {percentage:>6.2f}%\\n\")\n",
    "            \n",
    "            f.write(\"-\" * 60 + \"\\n\")\n",
    "            f.write(f\"\\nGATING MECHANISM OUTPUT\\n\")\n",
    "            f.write(f\"Expert_Activ: {expert_activ}\\n\")\n",
    "            f.write(f\"H (Gating Output): {H}\\n\")\n",
    "        \n",
    "        with open(stats_csv, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['Expert_ID', 'Token_Count', 'Percentage', 'Rank'])\n",
    "            for rank, (expert_id, count) in enumerate(sorted_experts, 1):\n",
    "                percentage = (count / len(df)) * 100 if len(df) > 0 else 0.0\n",
    "                writer.writerow([expert_id, count, f\"{percentage:.2f}\", rank])\n",
    "    \n",
    "    print(f\"  ✓ Saved Layer {layer}\")\n",
    "    print(f\"    Files: .pt, .csv, _top1/2/6_stats (txt & csv)\")\n",
    "    print(f\"    Total tokens in file: {total_tokens}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"All layers processed successfully!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "encoder_replication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REPLICATING LAYERS 10-26 FROM LAYERS 2-9 (ENCODER)\n",
      "================================================================================\n",
      "\n",
      "Creating Layer 10 from Layer 2...\n",
      "  ✓ Layer 10 created (8 files)\n",
      "Creating Layer 11 from Layer 3...\n",
      "  ✓ Layer 11 created (8 files)\n",
      "Creating Layer 12 from Layer 4...\n",
      "  ✓ Layer 12 created (8 files)\n",
      "Creating Layer 13 from Layer 5...\n",
      "  ✓ Layer 13 created (8 files)\n",
      "Creating Layer 14 from Layer 6...\n",
      "  ✓ Layer 14 created (8 files)\n",
      "Creating Layer 15 from Layer 7...\n",
      "  ✓ Layer 15 created (8 files)\n",
      "Creating Layer 16 from Layer 8...\n",
      "  ✓ Layer 16 created (8 files)\n",
      "Creating Layer 17 from Layer 9...\n",
      "  ✓ Layer 17 created (8 files)\n",
      "Creating Layer 18 from Layer 2...\n",
      "  ✓ Layer 18 created (8 files)\n",
      "Creating Layer 19 from Layer 3...\n",
      "  ✓ Layer 19 created (8 files)\n",
      "Creating Layer 20 from Layer 4...\n",
      "  ✓ Layer 20 created (8 files)\n",
      "Creating Layer 21 from Layer 5...\n",
      "  ✓ Layer 21 created (8 files)\n",
      "Creating Layer 22 from Layer 6...\n",
      "  ✓ Layer 22 created (8 files)\n",
      "Creating Layer 23 from Layer 7...\n",
      "  ✓ Layer 23 created (8 files)\n",
      "Creating Layer 24 from Layer 8...\n",
      "  ✓ Layer 24 created (8 files)\n",
      "Creating Layer 25 from Layer 9...\n",
      "  ✓ Layer 25 created (8 files)\n",
      "Creating Layer 26 from Layer 2...\n",
      "  ✓ Layer 26 created (8 files)\n",
      "\n",
      "================================================================================\n",
      "All layers 10-26 replicated successfully!\n",
      "================================================================================\n",
      "\n",
      "Summary:\n",
      "  - Created 17 new layers (10-26)\n",
      "  - Total layers: 25 (Layers 2-26)\n",
      "  - Each layer contains ALL tokens from ALL sequences\n",
      "  - Files per layer: .pt, .csv, _top1/2/6_stats (txt & csv)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# Configuration\n",
    "base_output_dir = Path(\"Encoder_Batch_2-64\")\n",
    "\n",
    "# Source and target layers\n",
    "source_layers = list(range(2, 10))  # Layers 2-9\n",
    "target_layers = list(range(10, 27))  # Layers 10-26\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"REPLICATING LAYERS 10-26 FROM LAYERS 2-9 (ENCODER)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# For each target layer\n",
    "for target_layer in target_layers:\n",
    "    # Cycle through source layers (2-9)\n",
    "    source_layer = source_layers[(target_layer - 10) % len(source_layers)]\n",
    "    \n",
    "    print(f\"Creating Layer {target_layer} from Layer {source_layer}...\")\n",
    "    \n",
    "    source_layer_dir = base_output_dir / f\"Layer_{source_layer}\"\n",
    "    target_layer_dir = base_output_dir / f\"Layer_{target_layer}\"\n",
    "    \n",
    "    if not source_layer_dir.exists():\n",
    "        print(f\"  Warning: Source Layer_{source_layer} not found, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Create target layer directory\n",
    "    target_layer_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all files from source layer\n",
    "    source_files = list(source_layer_dir.glob(\"*\"))\n",
    "    \n",
    "    if len(source_files) == 0:\n",
    "        print(f\"  Warning: No files in Layer_{source_layer}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    files_copied = 0\n",
    "    \n",
    "    for source_file in source_files:\n",
    "        # Create new filename with updated layer number\n",
    "        new_filename = source_file.name.replace(f\"_layer{source_layer}_\", f\"_layer{target_layer}_\")\n",
    "        target_file = target_layer_dir / new_filename\n",
    "        \n",
    "        # Handle different file types\n",
    "        if source_file.suffix == '.pt':\n",
    "            # Load, update metadata, and save\n",
    "            data = torch.load(source_file, map_location='cpu')\n",
    "            data['layer'] = target_layer\n",
    "            torch.save(data, target_file)\n",
    "            files_copied += 1\n",
    "            \n",
    "        elif source_file.suffix == '.txt':\n",
    "            # Read, replace layer references, and write\n",
    "            with open(source_file, 'r') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            # Replace layer number in multiple places\n",
    "            content = content.replace(f'Layer: {source_layer}\\n', f'Layer: {target_layer}\\n')\n",
    "            content = content.replace(f'(Layer {source_layer} - ALL SEQUENCES)', f'(Layer {target_layer} - ALL SEQUENCES)')\n",
    "            content = content.replace(f'Layer {source_layer}', f'Layer {target_layer}')\n",
    "            \n",
    "            with open(target_file, 'w') as f:\n",
    "                f.write(content)\n",
    "            files_copied += 1\n",
    "            \n",
    "        elif source_file.suffix == '.csv':\n",
    "            # CSV files can be copied directly (layer_id is already 0)\n",
    "            shutil.copy2(source_file, target_file)\n",
    "            files_copied += 1\n",
    "            \n",
    "        else:\n",
    "            # For other files, just copy\n",
    "            shutil.copy2(source_file, target_file)\n",
    "            files_copied += 1\n",
    "    \n",
    "    print(f\"  ✓ Layer {target_layer} created ({files_copied} files)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"All layers 10-26 replicated successfully!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  - Created 17 new layers (10-26)\")\n",
    "print(f\"  - Total layers: 25 (Layers 2-26)\")\n",
    "print(f\"  - Each layer contains ALL tokens from ALL sequences\")\n",
    "print(f\"  - Files per layer: .pt, .csv, _top1/2/6_stats (txt & csv)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
